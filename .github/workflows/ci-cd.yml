# This is a basic workflow to help you get started with Actions

name: CI/CD

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main and develop" branch
  push:
    branches: [ "main", "develop" ]
  pull_request:
    branches: [ "main", "develop" ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  Ruff_linter:
    # Set up operating system
    runs-on: ubuntu-latest
    
    defaults:
      run:
        shell: bash -l {0}

    # Docker Hub image that `postgres-job` executes in
    #container: node:latest
    # service containers to run with `postgres-job`
    steps:

    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
        
    - name: Check-out repository
      uses: actions/checkout@v2

      #- name: Install Python dependencies
      #  uses: py-actions/py-dependency-install@v4
        
    - uses: conda-incubator/setup-miniconda@v2
      with:
        miniconda-version: "latest"
        channels: bioconda, conda-forge, defaults
        use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
        auto-update-conda: true
        auto-activate-base: true
        
    - name: Install cPredictor pip
      run: |
            echo "begin: PATH=$PATH;"

            conda create -y --name cPredictor pip python=3.9 setuptools wheel

            conda activate cPredictor || true
            echo "after conda activate cPredictor: PATH=$PATH;"
            which cPredictor || true
            # Use cPredictor in ci-cd workflow

    - name: pip install ruff
      run: pip install ruff
      
    # Run the ruff linter and ignore the import package error E402
    - name: Run Ruff linter
      run: ruff check cPredictor/SVM_prediction.py --line-length 88 --extend-select C4,SIM,TCH,E4,E7,E9,F --ignore E402
      
  ci:
    needs: Ruff_linter
    # Set up operating system
    runs-on: ubuntu-latest
    
    defaults:
      run:
        shell: bash -l {0}

    # Docker Hub image that `postgres-job` executes in
    #container: node:latest
    # service containers to run with `postgres-job`
    steps:

    - name: Cleanup build folder
      run: |
        ls -la ./
        rm -rf ./* || true
        rm -rf ./.??* || true
        ls -la ./
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
        
    - name: Check-out repository
      uses: actions/checkout@v2

      #- name: Install Python dependencies
      #  uses: py-actions/py-dependency-install@v4
        
    - uses: conda-incubator/setup-miniconda@v2
      with:
        miniconda-version: "latest"
        channels: bioconda, conda-forge, defaults
        use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
        auto-update-conda: true
        auto-activate-base: true
        
    - name: Install cPredictor pip
      run: |
            echo "begin: PATH=$PATH;"

            conda create -y --name cPredictor pip python=3.9

            conda activate cPredictor || true
            echo "after conda activate cPredictor: PATH=$PATH;"
            which cPredictor || true
            # Use cPredictor in ci-cd workflow
      
    # Builds a wheel needed for the CD part
    - name: Build wheel of package
      run: pip wheel --no-deps -w dist .
      
    - name: Creating needed directories
      run: mkdir -p dist_artifacts data figures test_output_unit
      
    - name: Copying artifact to artifact dir
      run: cp dist/*.whl dist_artifacts/
  
    - name: Use the Upload Artifact GitHub Action
      uses: actions/upload-artifact@v4
      with: 
        name: my-artifact
        path: dist_artifacts/

    # Update pip
    - name: Update pip and setuptools
      run: pip install --upgrade pip setuptools wheel

    # Test if the created wheel file can be installed
    - name: Install wheel of package into conda env
      run: pip install dist/*.whl --force-reinstall

      # Test if a CLI function is able to run
    - name: Check CLI function
      run: SVM_predict --help
      
    # Download data into own directory
    - name: Download labels  
      run: curl -o data/training_labels_meta.csv https://zenodo.org/records/8096135/files/small_training_labels_meta.csv?download=1

    - name: Download test
      run: curl -o data/small_test.h5ad https://zenodo.org/records/8096135/files/small_test.h5ad?download=1

    - name: Download training
      run: curl -o data/cma_meta_atlas.h5ad https://zenodo.org/records/8096135/files/small_cma_meta_atlas.h5ad?download=1

    - name: Download dictionary of the cornea meta-atlas with colors
      run: curl -o data/colord.tsv https://zenodo.org/records/8096135/files/colord.tsv?download=1

    - name: Run unit tests
      run: |
        pytest cPredictor/tests/SVM_prediction_test.py -vvv --disable-pytest-warnings \
        --cov=./ --cov-report=xml

    - name: Upload code coverage ☂️
      uses: paambaati/codeclimate-action@v5.0.0
      env:
        CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}

  cd:
    # Only run this job if the "ci" job passes
    needs: ci
    
    # Only run this job if new work is pushed to "main"
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    # Set up operating system
    runs-on: ubuntu-latest

    # Define job steps
    steps:

    - name: Cleanup build folder
      run: |
        ls -la ./
        rm -rf ./* || true
        rm -rf ./.??* || true
        ls -la ./
        
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
        
    - name: Create dist dir
      run: mkdir -p dist

    - name: Download artifact
      uses: actions/download-artifact@v4
      with:
        name: my-artifact
        path: dist
  
    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: __token__
        password: ${{ secrets.PYPI_API_TOKEN }}

# TO DO: write unit tests and add Codecov
  test_model_cornea:
    # Set up operating system
    needs: ci

    runs-on: ubuntu-latest
    
    defaults:
      run:
        shell: bash -l {0}

    # Docker Hub image that `postgres-job` executes in
    #container: node:latest
    # service containers to run with `postgres-job`
    steps:
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
        
    - name: Check-out repository
      uses: actions/checkout@v2

      #- name: Install Python dependencies
      #  uses: py-actions/py-dependency-install@v4
        
    - uses: conda-incubator/setup-miniconda@v2
      with:
        miniconda-version: "latest"
        channels: bioconda, conda-forge, defaults
        use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
        auto-update-conda: true
        auto-activate-base: true

    - name: Install cPredictor pip
      run: |
            echo "begin: PATH=$PATH;"
            conda create -y --name cPredictor pip python=3.9
            conda activate cPredictor || true
            echo "after conda activate cPredictor: PATH=$PATH;"
            which cPredictor || true
            # Use cPredictor in ci-cd workflow

    - name: Create dist dir
      run: mkdir -p dist figures data test_output test

    - name: Download artifact
      uses: actions/download-artifact@v4
      with:
        name: my-artifact
        path: dist

    - name: Install git
      run: conda install git
      
    - name: Download ML tracking packages
      run: pip install dagshub mlflow

    # Installs from wheel if ci is finished
    - name: Install wheel of package into conda env
      run: pip install dist/*.whl --force-reinstall
      
    # Download data into own directory
    - name: Download labels  
      run: curl -o data/training_labels_meta.csv https://zenodo.org/records/8096135/files/training_labels_meta.csv?download=1
      
    - name: Download CV data
      run: curl -o test/cma_meta_atlas_rfe.h5ad https://zenodo.org/records/11098327/files/cma_meta_atlas_rfe.h5ad?download=1

    - name: Rename CV data
      run: mv test/cma_meta_atlas_rfe.h5ad test/cma_meta_atlas.h5ad
      
    # Pre-process 
    # Running prediction function
    - name: Running CV and logging results to DagsHub
      env:
        DH_key: ${{ secrets.DH_key }}
      run: python3 cPredictor/tests/cPredictor_test_model.py

